"""
SQL å·¥å…· - å•ä¸€ SQLTool ç±»ï¼šéªŒè¯ã€æ‰§è¡Œã€ç”Ÿæˆã€æ‰§è¡Œä¸è¯„ä¼°

å¯¹å¤–æš´éœ²ï¼š
- SQLTool(llm?, db?): ç»Ÿä¸€å…¥å£ï¼Œæ”¯æŒ validate_sql / execute_sql / generate_sql / execute_and_evaluate
- run_workflow / run_generate / run_execute_and_evaluate: ä¾› Orchestrator ä¸ ReAct æµç¨‹è°ƒç”¨
- ValidateSQLTool / ExecuteSQLTool / GenerateSQLTool / ExecuteAndEvaluateTool: è–„åŒ…è£…ï¼Œä¾› Registry æ³¨å†Œ
- SQLWorkflowTool: ç”Ÿæˆâ†’éªŒè¯â†’æ‰§è¡Œä¸è¯„ä¼° çš„å®Œæ•´æµç¨‹
"""

import json
import re
from dataclasses import dataclass, field
from typing import Any, TYPE_CHECKING

from chatdb.database.base import BaseDatabaseConnector
from chatdb.database.duckdb.syntax_rules import get_duckdb_syntax_rules
from chatdb.llm.base import BaseLLM
from chatdb.tools.base import BaseTool, ToolParameter, ToolResult
from chatdb.utils.logger import get_component_logger
from chatdb.utils.common import parse_json, clean_sql as _clean_sql_util, format_rows

from chatdb.core.react_state import ReActState, ReActPhase, ErrorType, AnalysisPhase

if TYPE_CHECKING:
    from chatdb.agents.base import AgentContext
    from chatdb.agents.semantic_parser import StructuredIntent


# ---------- å…¬å…±é€»è¾‘ ----------

DANGEROUS_KEYWORDS = [
    "DROP", "DELETE", "UPDATE", "INSERT", "TRUNCATE", "ALTER", "CREATE",
]


def check_sql_readonly(sql: str) -> list[str]:
    """åªè¯»å®‰å…¨æ£€æŸ¥ï¼šå¿…é¡» SELECTï¼Œç¦æ­¢å†™æ“ä½œå…³é”®è¯ã€‚è¿”å›é”™è¯¯åˆ—è¡¨ï¼Œç©ºè¡¨ç¤ºé€šè¿‡ã€‚"""
    errors: list[str] = []
    sql_upper = sql.upper().strip()
    if not sql_upper.startswith("SELECT"):
        errors.append("åªæ”¯æŒ SELECT æŸ¥è¯¢")
    for kw in DANGEROUS_KEYWORDS:
        if kw in sql_upper:
            errors.append(f"ç¦æ­¢ä½¿ç”¨ {kw} è¯­å¥")
    return errors


def check_sql_syntax(sql: str) -> list[str]:
    """åŸºç¡€è¯­æ³•æ£€æŸ¥ï¼šSELECTã€FROMã€æ‹¬å·åŒ¹é…ã€‚è¿”å›é”™è¯¯åˆ—è¡¨ï¼Œç©ºè¡¨ç¤ºé€šè¿‡ã€‚"""
    errors: list[str] = []
    sql_upper = sql.upper().strip()
    if not sql_upper.startswith("SELECT"):
        errors.append("SQL å¿…é¡»ä»¥ SELECT å¼€å¤´")
    if "FROM" not in sql_upper:
        errors.append("SQL å¿…é¡»åŒ…å« FROM å­å¥")
    if sql.count("(") != sql.count(")"):
        errors.append("æ‹¬å·ä¸åŒ¹é…")
    return errors


def check_sql_safety(sql: str) -> list[str]:
    """å®‰å…¨æ£€æŸ¥ï¼ˆå±é™©å…³é”®è¯ï¼‰ã€‚è¿”å›é”™è¯¯åˆ—è¡¨ã€‚"""
    errors: list[str] = []
    sql_upper = sql.upper()
    for kw in DANGEROUS_KEYWORDS:
        if kw in sql_upper:
            errors.append(f"ç¦æ­¢ä½¿ç”¨ {kw} è¯­å¥")
    return errors


def error_type_from_str(s: str) -> ErrorType:
    """å°† Agent/å·¥å…·è¿”å›çš„ error_type å­—ç¬¦ä¸²æ˜ å°„ä¸º ErrorType æšä¸¾ã€‚"""
    _map = {
        "unknown_column": ErrorType.UNKNOWN_COLUMN,
        "type_mismatch": ErrorType.TYPE_MISMATCH,
        "syntax_error": ErrorType.SYNTAX_ERROR,
        "no_data": ErrorType.NO_DATA,
    }
    return _map.get(s, ErrorType.OTHER)


# ---------- æ•°æ®ç±»ä¸é”™è¯¯æ¨¡å¼ ----------


@dataclass
class SQLCandidate:
    """SQL å€™é€‰é¡¹"""
    sql: str
    reason: str
    confidence: float = 1.0
    validation_status: str = "pending"
    validation_error: str | None = None


@dataclass
class EvaluationResult:
    """è¯„ä¼°ç»“æœ"""
    sql: str
    execution_success: bool = False
    rows: list[dict[str, Any]] = field(default_factory=list)
    row_count: int = 0
    execution_error: str | None = None
    diagnosis: str = ""
    error_type: ErrorType = ErrorType.NONE
    error_context: dict[str, Any] = field(default_factory=dict)
    refined: bool = False
    refined_sql: str = ""
    refinement_reason: str = ""
    summary: str = ""


ERROR_PATTERNS: dict[ErrorType, list[str]] = {
    ErrorType.UNKNOWN_COLUMN: [
        r"Binder Error.*column.*not found",
        r"Unknown column",
        r"no such column",
        r"does not exist",
        r"Referenced column.*not found",
    ],
    ErrorType.TYPE_MISMATCH: [
        r"Type mismatch",
        r"cannot compare",
        r"incompatible types",
        r"Conversion Error",
        r"Could not convert",
    ],
    ErrorType.SYNTAX_ERROR: [
        r"Parser Error",
        r"Syntax error",
        r"unexpected token",
        r"near \".*\"",
    ],
}

def _check_business(sql: str, yml_config: dict[str, Any]) -> tuple[list[str], list[str]]:
    """ä¸šåŠ¡è§„åˆ™æ£€æŸ¥ã€‚è¿”å› (errors, warnings)ã€‚"""
    errors: list[str] = []
    warnings: list[str] = []
    filters = yml_config.get("filters", {})
    rules = yml_config.get("rules", [])
    base_filter = filters.get("base_valid_data", {})
    if base_filter:
        expr = base_filter.get("expr", "")
        for field in ["ç»Ÿä¸€å‰”é™¤æ ‡ç­¾", "is_valid"]:
            if field in expr and field not in sql:
                warnings.append(f"å»ºè®®æ·»åŠ åŸºç¡€ç­›é€‰æ¡ä»¶ï¼ˆ{field}ï¼‰")
    for rule in rules:
        if rule.get("type") == "validate_filter":
            must_include = rule.get("must_include")
            if must_include:
                filter_def = filters.get(must_include, {})
                if filter_def.get("expr") and filter_def["expr"] not in sql:
                    warnings.append(f"å»ºè®®åŒ…å« {filter_def.get('label', must_include)} ç­›é€‰")
    return errors, warnings


# ---------- å•ä¸€ SQLTool ç±» ----------


class SQLTool:
    """
    ç»Ÿä¸€ SQL å·¥å…·ï¼šéªŒè¯ã€æ‰§è¡Œã€ç”Ÿæˆã€æ‰§è¡Œä¸è¯„ä¼°ã€‚

    - validate_sql: è¯­æ³•ä¸ä¸šåŠ¡è§„åˆ™æ ¡éªŒï¼ˆæ— éœ€ llm/dbï¼‰
    - execute_sql: åªè¯»æ‰§è¡Œå¹¶è¿”å›ç»“æœï¼ˆéœ€ db_connectorï¼‰
    - generate_sql: æ ¹æ®æ„å›¾ç”Ÿæˆ SQLï¼ˆéœ€ llmï¼‰
    - execute_and_evaluate: æ‰§è¡Œå¹¶è¯Šæ–­/ä¿®æ­£ï¼ˆéœ€ llm + db_connectorï¼‰
    """

    MAX_REFINE_ATTEMPTS = 2

    def __init__(
        self,
        llm: BaseLLM | None = None,
        db_connector: BaseDatabaseConnector | None = None,
    ):
        self.llm = llm
        self.db_connector = db_connector
        self._log = get_component_logger("SQLTool")

    def validate_sql(
        self,
        sql: str,
        yml_config: dict[str, Any] | None = None,
    ) -> ToolResult:
        """éªŒè¯ SQL è¯­æ³•ä¸ä¸šåŠ¡è§„åˆ™ã€‚"""
        self._log.info(f"éªŒè¯: {sql[:50]}...")
        errors: list[str] = []
        warnings: list[str] = []
        errors.extend(check_sql_syntax(sql))
        errors.extend(check_sql_safety(sql))
        if yml_config:
            biz_errors, biz_warnings = _check_business(sql, yml_config)
            errors.extend(biz_errors)
            warnings.extend(biz_warnings)
        is_valid = len(errors) == 0
        return ToolResult.ok(
            data={
                "is_valid": is_valid,
                "errors": errors,
                "warnings": warnings,
            },
            message="éªŒè¯é€šè¿‡" if is_valid else f"éªŒè¯å¤±è´¥: {len(errors)} ä¸ªé”™è¯¯",
        )

    async def execute_sql(self, sql: str, limit: int = 100) -> ToolResult:
        """æ‰§è¡Œåªè¯» SQL å¹¶è¿”å›ç»“æœã€‚"""
        if not self.db_connector:
            return ToolResult.fail("æœªé…ç½®æ•°æ®åº“è¿æ¥")
        self._log.info(f"æ‰§è¡Œ: {sql[:60]}...")
        errs = check_sql_readonly(sql)
        if errs:
            return ToolResult.fail(errs[0])
        try:
            rows = await self.db_connector.execute_query(sql)
            columns = list(rows[0].keys()) if rows else []
            return ToolResult.ok(
                data={
                    "rows": rows[:limit],
                    "row_count": len(rows),
                    "columns": columns,
                },
                message=f"æŸ¥è¯¢è¿”å› {len(rows)} è¡Œ",
            )
        except Exception as e:
            self._log.error(f"æ‰§è¡Œå¤±è´¥: {e}")
            return ToolResult.fail(f"SQL æ‰§è¡Œå¤±è´¥: {e}")

    # ---------- ç”Ÿæˆ SQLï¼ˆåŸ SQLGenerator é€»è¾‘ï¼‰ ----------

    def _get_table_schema(
        self,
        table_name: str,
        available_tables: list[dict[str, Any]] | None,
    ) -> dict[str, Any]:
        """è·å–è¡¨çš„ Schema ä¿¡æ¯
        
        è¿”å›ï¼š
            - table_name: è¡¨å
            - columns: åˆ—ä¿¡æ¯
            - row_count: è¡Œæ•°
            - create_table_sql: å»ºè¡¨ SQL
            - column_profiles: ä¸°å¯Œçš„åˆ—å…ƒä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        if not available_tables:
            return {"table_name": table_name, "columns": [], "row_count": 0}
        for table in available_tables:
            if table.get("table_name") == table_name:
                columns = table.get("columns_info") or table.get("columns", [])
                return {
                    "table_name": table_name,
                    "columns": columns,
                    "row_count": table.get("row_count", 0),
                    "create_table_sql": table.get("create_table_sql", ""),
                    # æ–°å¢ï¼šcolumn_profiles åŒ…å«å”¯ä¸€å€¼æ•°é‡ã€é«˜é¢‘å€¼ã€ç»Ÿè®¡ä¿¡æ¯
                    "column_profiles": table.get("column_profiles", []),
                }
        return {"table_name": table_name, "columns": [], "row_count": 0}

    def _format_columns_for_prompt(
        self, 
        columns: list[dict[str, Any]],
        column_profiles: list[dict[str, Any]] | None = None,
    ) -> str:
        """æ ¼å¼åŒ–åˆ—ä¿¡æ¯ä¾› LLM ç†è§£
        
        Args:
            columns: åŸºç¡€åˆ—ä¿¡æ¯ [{"name": "æœˆä»½", "type": "BIGINT"}, ...]
            column_profiles: ä¸°å¯Œçš„åˆ—å…ƒä¿¡æ¯ï¼ˆæ¥è‡ª meta_data.dbï¼‰ï¼ŒåŒ…å«ï¼š
                - unique_count: å”¯ä¸€å€¼æ•°é‡
                - summary: ç»Ÿè®¡æ‘˜è¦ï¼ˆèŒƒå›´/é«˜é¢‘å€¼ï¼‰
                - top_values: é«˜é¢‘å€¼åˆ—è¡¨
                - stats: æ•°å€¼ç»Ÿè®¡ï¼ˆmin/max/meanï¼‰
        
        è¿™äº›ä¿¡æ¯è®© LLM èƒ½å¤Ÿæ¨ç†å‡ºå¦‚ä½•åˆ†ç»„ã€ç­›é€‰ï¼Œè€Œä¸éœ€è¦ç¡¬ç¼–ç è§„åˆ™ã€‚
        ä¾‹å¦‚ï¼šLLM çœ‹åˆ° "æœˆä»½: æ•´æ•°, 12ä¸ªå”¯ä¸€å€¼, èŒƒå›´[202501~202512]" 
        å°±èƒ½æ¨ç†å‡ºè¿™æ˜¯æœˆåº¦æ•°æ®ï¼Œå¯ä»¥æŒ‰å­£åº¦åˆ†ç»„ã€‚
        """
        if not columns:
            return "æ— åˆ—ä¿¡æ¯"
        
        # æ„å»º column_profiles çš„ç´¢å¼•
        profiles_map: dict[str, dict] = {}
        if column_profiles:
            for p in column_profiles:
                profiles_map[p.get("name", "")] = p
        
        lines = []
        for col in columns:
            col_name = col.get("name", col.get("column_name", ""))
            col_type = col.get("type", col.get("column_type", ""))
            
            # åŸºç¡€ä¿¡æ¯
            line = f'- "{col_name}" ({col_type})'
            
            # å°è¯•ä» column_profiles è·å–ä¸°å¯Œä¿¡æ¯
            profile = profiles_map.get(col_name)
            if profile:
                # å”¯ä¸€å€¼æ•°é‡
                unique_count = profile.get("unique_count")
                if unique_count is not None:
                    line += f" [å”¯ä¸€å€¼:{unique_count}]"
                
                # ç»Ÿè®¡æ‘˜è¦ï¼ˆæœ€æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼‰
                summary = profile.get("summary", "")
                if summary:
                    # æˆªæ–­è¿‡é•¿çš„æ‘˜è¦
                    if len(summary) > 100:
                        summary = summary[:100] + "..."
                    line += f" -- {summary}"
            else:
                # é™çº§ï¼šä½¿ç”¨æ—§çš„ sample_values
                sample_values = col.get("sample_values", col.get("unique_values_top10", []))
                if sample_values:
                    line += f"  -- ç¤ºä¾‹: {', '.join(str(v) for v in sample_values[:5])}"
            
            lines.append(line)
        
        return "\n".join(lines)

    def _get_metrics_info(
        self,
        metric_ids: list[str],
        metrics_config: dict[str, Any],
        exclude_metric_id: str | None = None,
    ) -> str:
        """æŒ‡æ ‡å‚è€ƒä¿¡æ¯ï¼›exclude_metric_id ç”¨äºé¿å…ä¸ä¸Šæ–‡ã€ŒæŒ‡æ ‡çº¦æŸã€é‡å¤ã€‚"""
        if not metric_ids and not metrics_config:
            return "æ— æŒ‡å®šæŒ‡æ ‡"
        if exclude_metric_id and metric_ids == [exclude_metric_id] and not metrics_config:
            return "ï¼ˆå½“å‰æŒ‡æ ‡è§ä¸Šæ–‡ã€ŒæŒ‡æ ‡çº¦æŸã€ï¼‰"
        lines = []
        for mid in metric_ids:
            if mid == exclude_metric_id:
                continue
            if mid in metrics_config:
                m = metrics_config[mid]
                lines.append(f"- {mid}:")
                lines.append(f"  label: {m.get('label', '')}")
                expr = m.get('expr') or m.get('agg', '')
                if expr:
                    lines.append(f"  expr: {expr}")
                default_filters = m.get("default_filters") or m.get("filter_refs", [])
                if default_filters:
                    lines.append(f"  default_filters: {default_filters}")
                if m.get("description"):
                    lines.append(f"  description: {m.get('description')}")
        if not lines and metrics_config:
            for mid, m in metrics_config.items():
                if mid == exclude_metric_id:
                    continue
                expr = m.get('expr') or m.get('agg', '')
                lines.append(f"- {mid}: {m.get('label', '')} = {expr}")
        if exclude_metric_id and not lines:
            return "ï¼ˆå½“å‰æŒ‡æ ‡è§ä¸Šæ–‡ã€ŒæŒ‡æ ‡çº¦æŸã€ï¼‰"
        return "\n".join(lines) if lines else "æ— åŒ¹é…æŒ‡æ ‡"

    def _get_dimensions_info(self, dim_ids: list[str], dims_config: dict[str, Any]) -> str:
        if not dim_ids and not dims_config:
            return "æ— æŒ‡å®šç»´åº¦"
        lines = []
        for did in dim_ids:
            if did in dims_config:
                d = dims_config[did]
                lines.append(f"- {did}:")
                lines.append(f"  label: {d.get('label', '')}")
                lines.append(f"  column: {d.get('column', '')}")
        if not lines and dims_config:
            lines.append("å¯ç”¨ç»´åº¦ï¼š")
            for did, d in dims_config.items():
                col = d.get("column", did)
                lines.append(f'- {did}: {d.get("label", "")} -> åˆ— "{col}"')
        return "\n".join(lines) if lines else "æ— åŒ¹é…ç»´åº¦"

    def _get_filter_refs_info(self, filter_refs: list[str], filters_config: dict[str, Any]) -> str:
        if not filter_refs and not filters_config:
            return "æ— é¢„å®šä¹‰ç­›é€‰å™¨"
        lines = []
        for fid in filter_refs:
            if fid in filters_config:
                f = filters_config[fid]
                lines.append(f"- {fid}:")
                lines.append(f"  label: {f.get('label', '')}")
                lines.append(f"  expr: {f.get('expr', '')}")
                lines.append(f"  description: {f.get('description', '')}")
        if not lines and filters_config:
            lines.append("å¯ç”¨ç­›é€‰å™¨ï¼š")
            for fid, f in filters_config.items():
                lines.append(f"- {fid}: {f.get('label', '')} = {f.get('expr', '')}")
        return "\n".join(lines) if lines else "æ— åŒ¹é…ç­›é€‰å™¨"

    def _extract_metrics_from_filter_refs(
        self,
        filter_refs: list[str],
        filters_config: dict[str, Any],
        metrics_config: dict[str, Any],
    ) -> str:
        """
        ä» filter_refs ä¸­æå–æŒ‡æ ‡ç›¸å…³çš„ç­›é€‰è¡¨è¾¾å¼ã€‚
        
        å¾ˆå¤š YAML é…ç½®æŠŠæŒ‡æ ‡å®šä¹‰æ”¾åœ¨ filters èŠ‚ç‚¹ä¸‹ï¼ˆå¦‚ metric_flow, metric_grossï¼‰ï¼Œ
        è€Œä¸æ˜¯ metrics èŠ‚ç‚¹ã€‚è¿™ä¸ªæ–¹æ³•è¯†åˆ«è¿™äº›"æŒ‡æ ‡å‹ç­›é€‰å™¨"å¹¶æå–å…¶è¡¨è¾¾å¼ã€‚
        """
        if not filter_refs or not filters_config:
            return ""
        
        lines = []
        for fid in filter_refs:
            # è¯†åˆ«æŒ‡æ ‡å‹ç­›é€‰å™¨ï¼ˆä»¥ metric_ å¼€å¤´æˆ–åŒ…å«æŒ‡æ ‡ç›¸å…³å…³é”®è¯ï¼‰
            if fid.startswith("metric_") or any(kw in fid for kw in ["flow", "gross", "profit", "cost", "revenue"]):
                if fid in filters_config:
                    f = filters_config[fid]
                    expr = f.get("expr", "")
                    label = f.get("label", "")
                    if expr:
                        lines.append(f"- {label}ï¼ˆ{fid}ï¼‰: WHERE {expr}")
        
        # åŒæ—¶æ£€æŸ¥ metrics ä¸­æ˜¯å¦æœ‰ filter_refs å¼•ç”¨
        for metric_id, metric_def in metrics_config.items():
            metric_filter_refs = metric_def.get("filter_refs", [])
            for mfr in metric_filter_refs:
                if mfr in filters_config and mfr not in [l.split("ï¼ˆ")[1].split("ï¼‰")[0] for l in lines if "ï¼ˆ" in l]:
                    f = filters_config[mfr]
                    expr = f.get("expr", "")
                    if expr:
                        lines.append(f"- {metric_def.get('label', metric_id)} éœ€è¦: WHERE {expr}")
        
        return "\n".join(lines) if lines else ""

    def _get_filters_info(self, filters: list[dict], dims_config: dict[str, Any]) -> str:
        if not filters:
            return "æ— ç­›é€‰æ¡ä»¶"
        lines = []
        for f in filters:
            if "_agg_column" in f:
                lines.append(f"- èšåˆ: {f.get('_agg_func', 'SUM')}(\"{f.get('_agg_column')}\")")
                continue
            dim_id = f.get("dimension", f.get("column", ""))
            value = f.get("value", "")
            operator = f.get("operator", "=")
            if dim_id in dims_config:
                dim_def = dims_config[dim_id]
                column = dim_def.get("column", dim_id)
                terms = dim_def.get("terms", {})
                term_filter = None
                for term_id, term_def in terms.items():
                    if term_def.get("term") == value or value in term_def.get("synonyms", []):
                        term_filter = term_def.get("filter", "")
                        break
                if term_filter:
                    lines.append(f"- {dim_id}.{value} -> {term_filter}")
                else:
                    lines.append(f'- "{column}" {operator} \'{value}\'')
            else:
                lines.append(f'- "{dim_id}" {operator} \'{value}\'')
        return "\n".join(lines)

    def _clean_sql(self, sql: str) -> str:
        sql = re.sub(r"```sql\s*", "", sql)
        sql = re.sub(r"```\s*", "", sql)
        sql = sql.strip()
        
        # ä¿®å¤ä¸å®Œæ•´çš„ CASE è¯­å¥ï¼ˆLLM æœ‰æ—¶ä¼šæˆªæ–­ END å…³é”®å­—ï¼‰
        sql = self._fix_incomplete_case(sql)
        
        if not sql.endswith(";"):
            sql += ";"
        return sql
    
    def _fix_incomplete_case(self, sql: str) -> str:
        """
        ä¿®å¤ LLM ç”Ÿæˆçš„ä¸å®Œæ•´ CASE è¯­å¥
        
        é—®é¢˜åœºæ™¯ï¼šLLM åœ¨ ORDER BY ç­‰å­å¥ä¸­ç”Ÿæˆ CASE WHEN...THEN... åå¯èƒ½æˆªæ–­ END
        ä¾‹å¦‚ï¼šORDER BY CASE WHEN x THEN 'Q1' WHEN y THEN 'Q2'  (ç¼ºå°‘ END)
        """
        # ç»Ÿè®¡ CASE å’Œ END çš„æ•°é‡ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
        sql_upper = sql.upper()
        case_count = len(re.findall(r'\bCASE\b', sql_upper))
        end_count = len(re.findall(r'\bEND\b', sql_upper))
        
        if case_count > end_count:
            # æœ‰æœªé—­åˆçš„ CASEï¼Œå°è¯•åœ¨æœ«å°¾è¡¥å…… END
            missing = case_count - end_count
            self._log.warn(f"æ£€æµ‹åˆ° {missing} ä¸ªæœªé—­åˆçš„ CASE è¯­å¥ï¼Œå°è¯•ä¿®å¤")
            
            # ç§»é™¤æœ«å°¾åˆ†å·ï¼ˆå¦‚æœæœ‰ï¼‰
            sql_trimmed = sql.rstrip(';').rstrip()
            
            # æ·»åŠ ç¼ºå°‘çš„ END
            sql = sql_trimmed + ' END' * missing
        
        return sql

    def _parse_candidates(self, response: str) -> list[SQLCandidate]:
        candidates = []
        try:
            data = json.loads(response)
        except json.JSONDecodeError:
            json_match = re.search(r'\{[\s\S]*\}', response)
            data = json.loads(json_match.group()) if json_match else {}
        for c in data.get("candidates", []):
            sql = (c.get("sql", "") or "").strip()
            reason = c.get("reason", "")
            if sql:
                sql = self._clean_sql(sql)
                candidates.append(SQLCandidate(sql=sql, reason=reason, confidence=0.9))
        return candidates

    def _build_rule_based_sql(
        self,
        intent: Any,
        yml_config: dict[str, Any],
        table_schema: dict[str, Any] | None = None,
        state: Any = None,  # ReActStateï¼Œç”¨äºè·å–é¢„ç»„åˆçš„ required_filters
    ) -> str | None:
        if not intent.table_name:
            return None
        metrics_config = yml_config.get("metrics", {})
        dims_config = yml_config.get("dimensions", {})
        filters_config = yml_config.get("filters", {})
        available_columns = set()
        if table_schema and table_schema.get("columns"):
            for col in table_schema["columns"]:
                cn = col.get("name", col.get("column_name", ""))
                if cn:
                    available_columns.add(cn)
        
        # â˜… æ ¸å¿ƒæ”¹åŠ¨ï¼šè·å–å½“å‰æŒ‡æ ‡çš„ agg è¡¨è¾¾å¼
        agg_expr = None
        if state and hasattr(state, "current_metric_def") and state.current_metric_def:
            agg_expr = state.current_metric_def.get("agg", "")
        
        select_parts = []
        for dim_id in intent.dimensions:
            if dim_id in dims_config:
                col = dims_config[dim_id].get("column", dim_id)
                if col in available_columns or not available_columns:
                    select_parts.append(f'"{col}"')
            elif dim_id in available_columns:
                select_parts.append(f'"{dim_id}"')
        time_config = dims_config.get("time", {})
        col_map = time_config.get("column_map", {"year": "å¹´", "quarter": "å­£åº¦", "month": "æœˆä»½"})
        year_col = col_map.get("year", "å¹´")
        if year_col in available_columns or not available_columns:
            if intent.time.get("granularity", "year") in ("year", "quarter", "month"):
                select_parts.append(f'"{year_col}"')
        
        # â˜… ä½¿ç”¨ agg è¡¨è¾¾å¼ï¼ˆå¦‚æœæœ‰ï¼‰
        if agg_expr:
            metric_label = ""
            if state and hasattr(state, "current_metric_def"):
                metric_label = state.current_metric_def.get("label", "æŒ‡æ ‡")
            select_parts.append(f'{agg_expr} AS "{metric_label}"')
        else:
            # å›é€€åˆ°åŸé€»è¾‘
            for metric_id in intent.metrics:
                if metric_id in metrics_config:
                    m = metrics_config[metric_id]
                    expr = m.get("agg", m.get("expr", ""))
                    label = m.get("label", metric_id)
                    if expr:
                        select_parts.append(f'{expr} AS "{label}"')
        
        for f in intent.filters:
            if "_agg_column" in f:
                agg_col = f.get("_agg_column")
                agg_func = f.get("_agg_func", "SUM")
                if agg_col in available_columns or not available_columns:
                    select_parts.append(f'{agg_func}("{agg_col}") AS "{agg_col}_{agg_func}"')
        if not select_parts:
            return None
        
        # â˜… æ ¸å¿ƒæ”¹åŠ¨ï¼šä¼˜å…ˆä½¿ç”¨é¢„ç»„åˆçš„ required_filters
        where_parts = []
        if state and hasattr(state, "required_filters") and state.required_filters:
            for f in state.required_filters:
                expr = f.get("expr", "")
                if expr:
                    # å¤„ç†å¤šè¡Œ expr
                    expr_lines = [line.strip() for line in expr.strip().split("\n") if line.strip()]
                    where_parts.append(" ".join(expr_lines))
        
        # è¡¥å……æ—¶é—´ç­›é€‰
        if intent.time.get("year") and (year_col in available_columns or not available_columns):
            year_filter = f'"{year_col}" = {intent.time["year"]}'
            if year_filter not in " ".join(where_parts):
                where_parts.append(year_filter)
        
        # è¡¥å…… intent ä¸­çš„å…¶ä»–ç­›é€‰ï¼ˆä½†ä¸èƒ½ä¸ required_filters å†²çªï¼‰
        for f in intent.filters:
            if "_agg_column" in f:
                continue
            col = f.get("column", f.get("dimension", ""))
            val = f.get("value", "")
            op = f.get("operator", "=")
            if col and val and (col in available_columns or not available_columns):
                if isinstance(val, str):
                    filter_expr = f'"{col}" {op} \'{val}\''
                else:
                    filter_expr = f'"{col}" {op} {val}'
                # é¿å…é‡å¤
                if filter_expr not in " ".join(where_parts):
                    where_parts.append(filter_expr)
        
        sql = f'SELECT\n    {", ".join(select_parts)}\nFROM "{intent.table_name}"'
        if where_parts:
            sql += f"\nWHERE {' AND '.join(where_parts)}"
        group_cols = [p for p in select_parts if "AS" not in p and "(" not in p]
        if group_cols:
            sql += f"\nGROUP BY {', '.join(group_cols)}"
        if intent.limit:
            sql += f"\nLIMIT {intent.limit}"
        return sql + ";"

    def _build_sql_hard_rules(self, required_where_clauses: str, has_task_description: bool = False) -> str:
        """
        æ‹¼è£… SQL ç”Ÿæˆçš„ç¡¬çº¦æŸåˆ—è¡¨ï¼ˆé€šç”¨è¡¨è¿°ï¼Œä¸å†™æ­»ä¸šåŠ¡åˆ—å/å€¼ï¼‰ã€‚
        
        æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š
        - æ•°æ®ç­›é€‰ç”±è¯­ä¹‰è§£æå™¨å’Œ Planner ç¡®å®šï¼Œå·²åœ¨ "required_where_clauses" ä¸­ç»™å‡º
        - SQL ç”Ÿæˆå™¨åªè´Ÿè´£æŠ€æœ¯å®ç°ï¼Œä¸æ¨æ–­ä¸šåŠ¡é€»è¾‘
        - ä»»åŠ¡æè¿°ï¼ˆdescriptionï¼‰åªæè¿°åˆ†æåŠ¨ä½œï¼Œä¸åŒ…å«ç­›é€‰è¯­ä¹‰
        """
        rules = [
            '**åˆ—åå¿…é¡»ä»"è¡¨ç»“æ„"ä¸­é€‰æ‹©ï¼Œä¸èƒ½å‘æ˜ä¸å­˜åœ¨çš„åˆ—ï¼**',
            'ä½¿ç”¨åŒå¼•å·åŒ…è£¹åˆ—åï¼šSELECT "åˆ—å1", "åˆ—å2"',
            'å­—ç¬¦ä¸²å€¼ä½¿ç”¨å•å¼•å·ï¼šWHERE "åˆ—å" = \'å€¼\'',
            '**åªç”Ÿæˆ 1 ä¸ª SQLï¼Œå¿…é¡»ä¸å½“å‰ä»»åŠ¡ç±»å‹åŒ¹é…**',
            '**è‹¥ä¸Šæ–‡æŒ‡å®šäº†æŒ‡æ ‡èšåˆè¡¨è¾¾å¼ï¼ŒSELECT ä¸­å¿…é¡»ä½¿ç”¨è¯¥è¡¨è¾¾å¼**',
        ]
        
        if required_where_clauses.strip():
            rules.append(
                '**WHERE æ¡ä»¶å·²ç¡®å®š**ï¼šä¸Šæ–‡"å¿…é¡»åŒ…å«çš„ WHERE æ¡ä»¶"æ˜¯æ•°æ®çº¦æŸçš„**å®Œæ•´å®šä¹‰**ï¼Œç›´æ¥ä½¿ç”¨ï¼Œå¯è¿½åŠ  ANDï¼Œä¸å¯åˆ æ”¹'
            )
            rules.append(
                '**ç¦æ­¢æ¨æ–­é¢å¤–ç­›é€‰**ï¼šä»»åŠ¡æè¿°ï¼ˆdescriptionï¼‰åªæè¿°åˆ†æåŠ¨ä½œï¼Œä¸åŒ…å«ç­›é€‰é€»è¾‘ã€‚ä¸è¦æ ¹æ®æè¿°ä¸­çš„è¯æ±‡æ·»åŠ é¢å¤– WHERE æ¡ä»¶'
            )
        
        if has_task_description:
            rules.append(
                '**ä»»åŠ¡æè¿°è§£è¯»**ï¼šdescription ä¸­çš„è¯æ±‡ï¼ˆå¦‚"å¸‚åœºè´¹""ä»Šå¹´"ï¼‰æ˜¯ä¸Šä¸‹æ–‡è¯´æ˜ï¼Œå…¶å¯¹åº”çš„ç­›é€‰æ¡ä»¶å·²åœ¨"å¿…é¡»åŒ…å«çš„ WHERE æ¡ä»¶"ä¸­ï¼Œä¸è¦é‡å¤æ·»åŠ '
            )
        
        rules.append("åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—")
        return "\n".join(f"{i}. {r}" for i, r in enumerate(rules, 1))

    def _build_generation_prompt(
        self,
        intent: Any,
        yml_config: dict[str, Any],
        schema_text: str | None,
        table_schema: dict[str, Any] | None,
        current_task: dict[str, Any] | None = None,
        state: Any = None,  # ReActStateï¼Œç”¨äºè·å–æ³¨å…¥çš„æŒ‡æ ‡å®šä¹‰
    ) -> str:
        columns_info = "æ— åˆ—ä¿¡æ¯"
        if table_schema and table_schema.get("columns"):
            # ä½¿ç”¨ column_profiles ä¸°å¯Œåˆ—ä¿¡æ¯ï¼ˆåŒ…å«å”¯ä¸€å€¼æ•°é‡ã€é«˜é¢‘å€¼ã€ç»Ÿè®¡ä¿¡æ¯ï¼‰
            column_profiles = table_schema.get("column_profiles", [])
            columns_info = self._format_columns_for_prompt(
                table_schema["columns"], 
                column_profiles=column_profiles
            )
        elif schema_text:
            columns_info = schema_text
        
        # â˜… æ ¸å¿ƒæ”¹åŠ¨ï¼šä» state è·å–ç»“æ„åŒ–çš„æŒ‡æ ‡å®šä¹‰å’Œå¿…é¡»ç­›é€‰å™¨
        metric_constraint = ""
        required_where_clauses = ""
        
        if state and hasattr(state, "current_metric_def") and state.current_metric_def:
            metric_def = state.current_metric_def
            metric_name = getattr(state, "current_metric", "")
            agg_expr = metric_def.get("agg", "")
            filter_refs = metric_def.get("filter_refs", [])
            
            metric_constraint = f"""
## æŒ‡æ ‡çº¦æŸ
- æŒ‡æ ‡ID: {metric_name}
- å«ä¹‰: {metric_def.get('label', '')}
- èšåˆè¡¨è¾¾å¼ï¼ˆå¿…é¡»ä½¿ç”¨ï¼‰: {agg_expr}
- é»˜è®¤ç­›é€‰å™¨: {filter_refs}
"""
        
        if state and hasattr(state, "required_filters") and state.required_filters:
            where_parts = []
            for f in state.required_filters:
                where_parts.append(f"  -- {f['id']}: {f['label']}\n  ({f['expr']})")
            required_where_clauses = f"""
## å¿…é¡»åŒ…å«çš„ WHERE æ¡ä»¶
ä»¥ä¸‹æ¡ä»¶å¿…é¡»**å®Œæ•´**å‡ºç°åœ¨ WHERE å­å¥ä¸­ï¼ˆå¯è¿½åŠ  ANDï¼Œä¸å¯åˆ æ”¹ï¼‰ï¼š

{chr(10).join(where_parts)}
"""
        
        has_required_where = bool(
            state and getattr(state, "required_filters", None)
        )
        current_metric_id = (
            getattr(state, "current_metric", None)
            if state and getattr(state, "current_metric_def", None) else None
        )

        # æŒ‡æ ‡ï¼šæœ‰ã€ŒæŒ‡æ ‡çº¦æŸã€æ—¶æ’é™¤å½“å‰æŒ‡æ ‡ï¼Œé¿å…é‡å¤
        metrics_info = self._get_metrics_info(
            intent.metrics,
            yml_config.get("metrics", {}),
            exclude_metric_id=current_metric_id,
        )
        dimensions_info = self._get_dimensions_info(
            intent.dimensions, yml_config.get("dimensions", {})
        )
        # ç­›é€‰ï¼šæœ‰ã€Œå¿…é¡»åŒ…å«çš„ WHERE æ¡ä»¶ã€æ—¶ä¸å†é‡å¤é¢„å®šä¹‰ç­›é€‰å™¨ä¸æ˜ å°„
        if has_required_where:
            filter_refs_info = "ï¼ˆè§ä¸Šæ–‡ã€Œå¿…é¡»åŒ…å«çš„ WHERE æ¡ä»¶ã€ï¼‰"
            filters_info = ""
        else:
            filter_refs_info = self._get_filter_refs_info(
                intent.filter_refs, yml_config.get("filters", {})
            )
            filters_info = self._get_filters_info(
                intent.filters, yml_config.get("dimensions", {})
            )

        # ä» filter_refs æå–æŒ‡æ ‡ç›¸å…³ç­›é€‰ï¼ˆå·²æœ‰ã€Œå¿…é¡»åŒ…å«çš„ WHERE æ¡ä»¶ã€æ—¶ä¸é‡å¤ç½—åˆ—ï¼‰
        if not has_required_where:
            metrics_from_filters = self._extract_metrics_from_filter_refs(
                intent.filter_refs, yml_config.get("filters", {}), yml_config.get("metrics", {})
            )
            if metrics_from_filters:
                if metrics_info == "æ— æŒ‡å®šæŒ‡æ ‡" or metrics_info == "æ— åŒ¹é…æŒ‡æ ‡":
                    metrics_info = metrics_from_filters
                else:
                    metrics_info += f"\n\n### ä»ç­›é€‰å™¨æ¨æ–­çš„æŒ‡æ ‡æ¡ä»¶\n{metrics_from_filters}"
        
        # æ„å»ºä»»åŠ¡æŒ‡ä»¤ï¼ˆé€šç”¨ï¼šä¸ç»‘å®šå…·ä½“ pipeline åç§°ï¼‰
        task_instruction = ""
        
        # â˜… æ¶æ„æ”¹é€ ï¼šä» state è·å–å£å¾„è®¾è®¡ç»“æœï¼Œä¸å†ç”¨å…³é”®è¯åˆ¤æ–­
        # numerator_filters ç”± CalibrationDesigner æ™ºèƒ½å†³å®šï¼Œå­˜å‚¨åœ¨ state.numerator_filters
        numerator_filters = getattr(state, "numerator_filters", []) if state else []
        is_ratio_calculation = bool(numerator_filters)  # æœ‰åˆ†å­ç­›é€‰å°±æ˜¯å æ¯”è®¡ç®—
        
        if current_task:
            task_type = current_task.get("task_type", current_task.get("type", ""))
            task_id = current_task.get("task_id", current_task.get("id", ""))
            task_desc = current_task.get("description", "")
            task_notes = current_task.get("notes", [])
            current_dim = current_task.get("current_dimension", "")
            time_granularity = current_task.get("time_granularity", "")
            intent_hint = current_task.get("intent_hint", "")
            parent_summary = current_task.get("parent_results_summary", "")
            depends_on = current_task.get("depends_on", [])
            
            # â˜… è·å– Planner çš„ SQL ä¿®å¤å»ºè®®ï¼ˆé‡è¯•æ—¶ä½¿ç”¨ï¼‰
            retry_hint = current_task.get("retry_hint", "")
            retry_count = current_task.get("retry_count", 0)
            
            task_instruction = f"""
## ğŸ¯ å½“å‰åˆ†æä»»åŠ¡
- ä»»åŠ¡ ID: {task_id}
- ä»»åŠ¡ç±»å‹: {task_type}
- ä»»åŠ¡æè¿°: {task_desc}
"""
            if task_notes:
                task_instruction += f"- æ³¨æ„äº‹é¡¹: {'; '.join(str(n) for n in task_notes)}\n"
            if current_dim:
                task_instruction += f"- å½“å‰åˆ†æç»´åº¦: {current_dim}\n"
            if time_granularity:
                task_instruction += f"- æ—¶é—´ç²’åº¦: {time_granularity}\n"
            if depends_on:
                task_instruction += f"- ä¾èµ–ä»»åŠ¡: {', '.join(depends_on)}\n"
            if parent_summary:
                task_instruction += f"- ä¸Šæ¸¸ç»“æœæ‘˜è¦: {parent_summary}\n"
            
            # å¦‚æœæœ‰ retry_hintï¼Œæ˜¾ç¤º SQL ä¿®å¤å»ºè®®
            if retry_hint:
                task_instruction += f"""
### ğŸ”´ SQL ä¿®å¤å»ºè®®ï¼ˆç¬¬ {retry_count} æ¬¡é‡è¯•ï¼‰
ä¸Šä¸€æ¬¡ SQL æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å»ºè®®ä¿®å¤ï¼š
{retry_hint}
"""
            
            if intent_hint:
                task_instruction += f"""
### ğŸ’¡ æ‰§è¡Œæ„å›¾
{intent_hint}
"""
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ å…·ä½“æŒ‡å¯¼
            if task_type == "trend":
                task_instruction += """
### âš ï¸ è¶‹åŠ¿åˆ†æè§„åˆ™
- **å¿…é¡»** æŒ‰æ—¶é—´ç»´åº¦ï¼ˆå¹´/æœˆï¼‰GROUP BY
- åªç”Ÿæˆ **1 ä¸ª** è¶‹åŠ¿ SQLï¼Œä¸è¦ç”Ÿæˆå…¶ä»–ç»´åº¦çš„ SQL
- ç»“æœåº”è¯¥æŒ‰æ—¶é—´ **å‡åº** æ’åº
- ä¸è¦æŒ‰å…¶ä»–ç»´åº¦åˆ†ç»„
"""
            elif task_type == "source":
                dim_hint = f"ã€Œ{current_dim}ã€" if current_dim else "æŒ‡å®šç»´åº¦"
                task_instruction += f"""
### âš ï¸ æ¥æºåˆ†æè§„åˆ™
- **å¿…é¡»** æŒ‰ç»´åº¦ {dim_hint} GROUP BY åˆ†ææ¥æºæ„æˆ
- åªç”Ÿæˆ **1 ä¸ª** æŒ‰ {dim_hint} åˆ†ç»„çš„ SQL
- **ä¸è¦** ç”Ÿæˆè¶‹åŠ¿æˆ–å…¶ä»–ç»´åº¦çš„ SQL
- æŒ‰æ•°å€¼ **é™åº** æ’åºï¼Œä¾¿äºçœ‹ top è´¡çŒ®
"""
            elif task_type == "comparison":
                task_instruction += """
### âš ï¸ å¯¹æ¯”åˆ†æè§„åˆ™
- éœ€è¦å¯¹æ¯”ä¸¤ä¸ªæ—¶é—´æ®µæˆ–æ¡ä»¶
- è®¡ç®—å·®å€¼æˆ–å¢é•¿ç‡
- ç»“æœåº”åŒ…å«å¯¹æ¯”åŸºå‡†å’Œå¯¹æ¯”å€¼
"""
            elif task_type == "drilldown":
                task_instruction += """
### âš ï¸ ä¸‹é’»åˆ†æè§„åˆ™
- åœ¨ä¸Šä¸€æ­¥ç»“æœåŸºç¡€ä¸Šè¿›ä¸€æ­¥ç»†åˆ†
- å¢åŠ ç­›é€‰æ¡ä»¶æˆ–æ›´ç»†ç²’åº¦çš„ç»´åº¦
- ä¿ç•™ä¸Šæ¸¸çš„ç­›é€‰æ¡ä»¶
"""
        
        # â˜…â˜…â˜… å æ¯”è®¡ç®—è§„åˆ™ï¼ˆåŸºäºå£å¾„è®¾è®¡ç»“æœï¼Œéå…³é”®è¯åˆ¤æ–­ï¼‰â˜…â˜…â˜…
        # å¦‚æœ CalibrationDesigner è¯†åˆ«å‡ºè¿™æ˜¯å æ¯”è®¡ç®—ï¼Œä¼šæŠŠåˆ†å­ç­›é€‰æ”¾å…¥ state.numerator_filters
        # SQLTool åªéœ€è¦æ ¹æ®è¿™ä¸ªç»“æ„ç”Ÿæˆæ­£ç¡®çš„ CASE WHEN
        if is_ratio_calculation and numerator_filters:
            task_instruction += f"""
### ğŸ¯ å æ¯”è®¡ç®—è§„åˆ™ï¼ˆç”±å£å¾„è®¾è®¡å™¨ç¡®å®šï¼‰
è¿™æ˜¯ä¸€ä¸ª**å æ¯”è®¡ç®—**ä»»åŠ¡ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ç­›é€‰æ¡ä»¶ï¼š

**åˆ†å­ç­›é€‰**ï¼ˆåªå½±å“åˆ†å­ï¼Œç”¨ CASE WHEN å®ç°ï¼‰ï¼š
"""
            for f in numerator_filters:
                task_instruction += f"  - {f.get('label', f.get('id', ''))}: {f.get('expr', '')}\n"
            
            task_instruction += """
**æ­£ç¡®å†™æ³•ç¤ºä¾‹**ï¼š
```sql
SELECT 
  SUM(CASE WHEN <åˆ†å­æ¡ä»¶> THEN "é‡‘é¢" ELSE 0 END) * 1.0 
  / SUM("é‡‘é¢") AS ratio
FROM ...
WHERE <å…¨å±€ç­›é€‰æ¡ä»¶>  -- åˆ†å­ç­›é€‰å·²é€šè¿‡ CASE WHEN å¤„ç†ï¼Œä¸è¦é‡å¤æ”¾åœ¨è¿™é‡Œï¼
```

âš ï¸ **ç¦æ­¢**æŠŠåˆ†å­ç­›é€‰æ”¾å…¥ WHERE å­å¥ï¼Œå¦åˆ™åˆ†æ¯ä¹Ÿä¼šè¢«é™åˆ¶ï¼Œå¯¼è‡´å æ¯”æ’ç­‰äº 1ï¼
"""
        
        if filters_info:
            filter_section = f"## ç­›é€‰ï¼ˆå‚è€ƒï¼‰\n{filter_refs_info}\n\n## ç­›é€‰æ¡ä»¶æ˜ å°„\n{filters_info}"
        else:
            filter_section = f"## ç­›é€‰ï¼ˆå‚è€ƒï¼‰\n{filter_refs_info}"
        
        # â˜… çŠ¶æ€éš”ç¦»ï¼šæœ‰ä»»åŠ¡ä¸Šä¸‹æ–‡æ—¶ï¼Œä¸æ˜¾ç¤ºç”¨æˆ·åŸå§‹é—®é¢˜ï¼Œåªæ˜¾ç¤ºä»»åŠ¡æè¿°
        if current_task:
            # å­ä»»åŠ¡åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡æè¿°ï¼Œå®Œå…¨éš”ç¦»ç”¨æˆ·åŸå§‹é—®é¢˜
            query_section = ""  # ä¸å†æ˜¾ç¤º raw_query
        else:
            # æ²¡æœ‰ä»»åŠ¡ä¸Šä¸‹æ–‡æ—¶ï¼Œç›´æ¥æ ¹æ® raw_query ç”Ÿæˆ
            query_section = f"""## ç”¨æˆ·æŸ¥è¯¢
{intent.raw_query}"""
        
        return f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå¯æ‰§è¡Œçš„ SQLã€‚
{task_instruction}
{metric_constraint}
{required_where_clauses}
{query_section}
## è¡¨å
{intent.table_name}

## è¡¨ç»“æ„ï¼ˆå¯ç”¨åˆ—å - åªèƒ½ä½¿ç”¨è¿™äº›åˆ—ï¼ï¼‰
{columns_info}

## ç»“æ„åŒ–æ„å›¾
- intent_type: {intent.intent_type}
- metrics: {intent.metrics}
- dimensions: {intent.dimensions}
- filter_refs: {intent.filter_refs}
- time: {json.dumps(intent.time, ensure_ascii=False)}
- filters: {json.dumps(intent.filters, ensure_ascii=False)}
- exclusions: {intent.exclusions}
- order_by: {intent.order_by}
- limit: {intent.limit}

## æŒ‡æ ‡å®šä¹‰ï¼ˆå‚è€ƒï¼‰
{metrics_info}

## ç»´åº¦å®šä¹‰ï¼ˆå‚è€ƒï¼‰
{dimensions_info}

{filter_section}

## DuckDB SQL è§„èŒƒ
{get_duckdb_syntax_rules()}

### ç¡¬çº¦æŸ
{self._build_sql_hard_rules(required_where_clauses, has_task_description=bool(current_task))}

## è¾“å‡ºè¦æ±‚
ä¸¥æ ¼è¾“å‡º JSONï¼Œ**åªç”Ÿæˆ 1 ä¸ªæœ€åŒ¹é…å½“å‰ä»»åŠ¡çš„ SQL**ï¼š
{{
  "candidates": [
    {{ "sql": "SELECT ... FROM ... WHERE ... GROUP BY ...", "reason": "ä¸€å¥è¯è§£é‡Šä¸šåŠ¡é€»è¾‘å’Œå£å¾„é€‰æ‹©" }}
  ]
}}
"""

    async def _generate_candidates(
        self,
        intent: Any,
        yml_config: dict[str, Any],
        schema_text: str | None = None,
        table_schema: dict[str, Any] | None = None,
        current_task: dict[str, Any] | None = None,
        state: Any = None,  # ReActState
    ) -> list[SQLCandidate]:
        prompt = self._build_generation_prompt(intent, yml_config, schema_text, table_schema, current_task, state)
        system = "ä½ æ˜¯ SQL ç”Ÿæˆä¸“å®¶ã€‚æ ¹æ®ç»“æ„åŒ–æ„å›¾å’Œè¡¨ç»“æ„ç”Ÿæˆ DuckDB SQLã€‚æ ¸å¿ƒåŸåˆ™ï¼šåªä½¿ç”¨æä¾›çš„åˆ—åï¼Œç»ä¸å‘æ˜ä¸å­˜åœ¨çš„åˆ—ï¼›åˆ—åç”¨åŒå¼•å·ï¼Œå­—ç¬¦ä¸²å€¼ç”¨å•å¼•å·ã€‚ä¸¥æ ¼è¾“å‡º JSONï¼›æ¯ä¸ª SQL å¯æ‰§è¡Œï¼›reason è¯´æ˜ä¸šåŠ¡é€»è¾‘ã€‚"
        if state and getattr(state, "required_filters", None):
            system += " å¿…é¡»å®Œæ•´åŒ…å«ä¸Šæ–‡æŒ‡å®šçš„ç­›é€‰æ¡ä»¶ï¼Œä¸èƒ½é—æ¼ã€‚"
        try:
            response = await self.llm.chat(
                prompt=prompt,
                system_prompt=system,
                caller_name="generate_sql",
            )
            candidates = self._parse_candidates(response)
            if candidates:
                self._log.observe(f"ç”Ÿæˆ {len(candidates)} ä¸ªå€™é€‰ SQL")
                return candidates
        except Exception as e:
            self._log.error(f"LLM ç”Ÿæˆå¤±è´¥: {e}")
        fallback_sql = self._build_rule_based_sql(intent, yml_config, table_schema, state)
        if fallback_sql:
            return [SQLCandidate(sql=fallback_sql, reason="åŸºäºè§„åˆ™æ¨¡æ¿ç”Ÿæˆ", confidence=0.6)]
        return []

    async def generate_sql(
        self,
        intent: "StructuredIntent | dict",
        schema_text: str = "",
        yml_config: dict[str, Any] | None = None,
        available_tables: list[dict] | None = None,
        current_task: dict[str, Any] | None = None,
        state: Any = None,  # ReActState
        **kwargs: Any,
    ) -> ToolResult:
        """æ ¹æ®ç»“æ„åŒ–æ„å›¾ç”Ÿæˆ SQLã€‚"""
        if not self.llm:
            return ToolResult.fail("æœªé…ç½® LLMï¼Œæ— æ³•ç”Ÿæˆ SQL")
        from chatdb.agents.semantic_parser import StructuredIntent
        intent_obj = StructuredIntent.from_dict(intent) if isinstance(intent, dict) else intent
        table_schema = self._get_table_schema(intent_obj.table_name, available_tables or [])
        candidates = await self._generate_candidates(
            intent_obj,
            yml_config or {},
            schema_text or None,
            table_schema,
            current_task,
            state,  # ä¼ å…¥ state
        )
        if not candidates:
            return ToolResult.fail("æ— æ³•ç”Ÿæˆæœ‰æ•ˆ SQL")
        c = candidates[0]
        return ToolResult.ok(
            data={
                "sql": c.sql,
                "reason": c.reason,
                "candidates": [
                    {"sql": x.sql, "reason": x.reason, "confidence": x.confidence}
                    for x in candidates
                ],
            },
            message="SQL ç”ŸæˆæˆåŠŸ",
        )

    # ---------- æ‰§è¡Œä¸è¯„ä¼°ï¼ˆåŸ ResultEvaluator é€»è¾‘ï¼‰ ----------

    def _classify_error(self, error_msg: str) -> ErrorType:
        for error_type, patterns in ERROR_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, error_msg, re.IGNORECASE):
                    return error_type
        return ErrorType.OTHER

    def _extract_error_context(
        self,
        error_msg: str,
        error_type: ErrorType,
        state: ReActState | None = None,
    ) -> dict[str, Any]:
        context: dict[str, Any] = {}
        if error_type == ErrorType.UNKNOWN_COLUMN:
            match = re.search(r'column\s+"?([^"]+)"?\s+not found', error_msg, re.IGNORECASE)
            if match:
                context["wrong_column"] = match.group(1)
                if state and state.available_columns:
                    alternatives = self._find_alternatives(match.group(1), state.available_columns)
                    context["alternatives"] = alternatives
                    context["has_alternative"] = bool(alternatives)
        elif error_type == ErrorType.TYPE_MISMATCH:
            match = re.search(r"cannot compare\s+(\w+)\s+and\s+(\w+)", error_msg, re.IGNORECASE)
            if match:
                context["type1"], context["type2"] = match.group(1), match.group(2)
        return context

    def _find_alternatives(self, wrong_col: str, columns: list[dict[str, Any]]) -> list[str]:
        alternatives = []
        wrong_lower = wrong_col.lower()
        for col in columns:
            col_name = col.get("name", col.get("column_name", ""))
            if wrong_lower in col_name.lower() or col_name.lower() in wrong_lower:
                alternatives.append(col_name)
        return list(set(alternatives))[:5]

    async def _execute_sql_internal(self, eval_result: EvaluationResult) -> EvaluationResult:
        if not self.db_connector:
            eval_result.execution_success = False
            eval_result.execution_error = "æœªé…ç½®æ•°æ®åº“è¿æ¥"
            return eval_result
        try:
            rows = await self.db_connector.execute_query(eval_result.sql)
            eval_result.rows = rows
            eval_result.row_count = len(rows)
            eval_result.execution_success = True
            eval_result.execution_error = None
            eval_result.error_type = ErrorType.NONE
            self._log.observe(f"æ‰§è¡ŒæˆåŠŸ: {len(rows)} è¡Œ")
        except Exception as e:
            eval_result.execution_success = False
            eval_result.execution_error = str(e)
            eval_result.error_type = self._classify_error(str(e))
            self._log.warn(f"æ‰§è¡Œå¤±è´¥: {e}")
        return eval_result

    def _build_diagnose_prompt(
        self,
        eval_result: EvaluationResult,
        intent: Any,
        schema_text: str | None,
    ) -> str:
        prompt = f"""è¯·è¯Šæ–­ä»¥ä¸‹ SQL çš„é—®é¢˜å¹¶ç»™å‡ºæœ€å°ä¿®æ­£ã€‚

## å½“å‰ SQL
{eval_result.sql}

## é”™è¯¯ç±»å‹
{eval_result.error_type.value}

## æ•°æ®åº“é”™è¯¯
{eval_result.execution_error}
"""
        if eval_result.error_context:
            if eval_result.error_context.get("wrong_column"):
                prompt += f"\n## å‡ºé”™å…ƒç´ \n{eval_result.error_context['wrong_column']}\n"
            if eval_result.error_context.get("alternatives"):
                prompt += f"\n## å¯ç”¨æ›¿ä»£\n{', '.join(eval_result.error_context['alternatives'])}\n"
        if intent:
            prompt += f"\n## ç”¨æˆ·åŸå§‹æŸ¥è¯¢\n{intent.raw_query}\n"
        if schema_text:
            prompt += f"\n## è¡¨ Schema\n{schema_text[:2000]}\n"
        prompt += """
## è¾“å‡ºè¦æ±‚
```json
{ "diagnosis": "ä¸€å¥è¯è¯´æ˜é—®é¢˜", "refined_sql": "ä¿®æ­£åçš„å®Œæ•´ SQL" }
```
åŸåˆ™ï¼šåªæ”¹å‡ºé”™éƒ¨åˆ†ï¼Œä¿æŒå…¶ä»–ç»“æ„ä¸å˜ã€‚åªè¾“å‡º JSONã€‚"""
        return prompt

    async def _diagnose_and_refine(
        self,
        eval_result: EvaluationResult,
        intent: Any,
        yml_config: dict[str, Any],
        schema_text: str | None,
    ) -> EvaluationResult:
        prompt = self._build_diagnose_prompt(eval_result, intent, schema_text)
        system = "ä½ æ˜¯ SQL è°ƒè¯•ä¸“å®¶ã€‚è¯Šæ–­é”™è¯¯åŸå› ï¼Œç»™å‡ºæœ€å°ä¿®æ­£ã€‚åªæ”¹å‡ºé”™éƒ¨åˆ†ï¼Œè¾“å‡ºæ¸…æ™° JSONã€‚"
        try:
            response = await self.llm.chat(
                prompt=prompt,
                system_prompt=system,
                caller_name="diagnose_and_refine",
            )
            result = parse_json(response)
            eval_result.diagnosis = result.get("diagnosis", "")
            refined_sql = result.get("refined_sql", "")
            if refined_sql and refined_sql != eval_result.sql:
                eval_result.refined = True
                eval_result.refined_sql = _clean_sql_util(refined_sql)
                eval_result.refinement_reason = eval_result.diagnosis
                self._log.reflect(f"è¯Šæ–­: {eval_result.diagnosis[:100]}")
            else:
                eval_result.refined = False
        except Exception as e:
            self._log.error(f"è¯Šæ–­å¤±è´¥: {e}")
        return eval_result

    async def _generate_summary_internal(
        self,
        eval_result: EvaluationResult,
        user_query: str,
        intent: Any,
    ) -> EvaluationResult:
        if eval_result.row_count == 0:
            eval_result.summary = "æŸ¥è¯¢æœªè¿”å›ç»“æœã€‚"
            return eval_result
        sample = eval_result.rows[:10]
        prompt = f"""è¯·æ ¹æ®æŸ¥è¯¢ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {user_query}

æŸ¥è¯¢ç»“æœï¼ˆå…± {eval_result.row_count} è¡Œï¼Œå‰ {len(sample)} è¡Œï¼‰:
{format_rows(sample)}

è¯·ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“ï¼Œçªå‡ºå…³é”®æ•°æ®ã€‚"""
        try:
            response = await self.llm.chat(
                prompt=prompt,
                system_prompt="ä½ æ˜¯æ•°æ®åˆ†æä¸“å®¶ï¼Œè¯·ç®€æ´å›ç­”ã€‚",
                caller_name="generate_summary",
            )
            eval_result.summary = response.strip()
        except Exception as e:
            self._log.error(f"æ€»ç»“å¤±è´¥: {e}")
            eval_result.summary = f"æŸ¥è¯¢è¿”å› {eval_result.row_count} è¡Œç»“æœã€‚"
        return eval_result

    async def execute_and_evaluate(
        self,
        sql: str,
        schema_text: str = "",
        intent: Any = None,
        yml_config: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> ToolResult:
        """æ‰§è¡Œ SQL å¹¶è¯Šæ–­/ä¿®æ­£ã€‚"""
        if not self.llm or not self.db_connector:
            return ToolResult.fail("æœªé…ç½® LLM æˆ–æ•°æ®åº“è¿æ¥ï¼Œæ— æ³•æ‰§è¡Œä¸è¯„ä¼°")
        eval_result = EvaluationResult(sql=sql)
        eval_result = await self._execute_sql_internal(eval_result)
        attempts = 0
        while not eval_result.execution_success and attempts < self.MAX_REFINE_ATTEMPTS:
            self._log.info(f"å°è¯•ä¿®æ­£ (ç¬¬ {attempts + 1} æ¬¡)")
            eval_result = await self._diagnose_and_refine(
                eval_result, intent, yml_config or {}, schema_text or None,
            )
            if eval_result.refined:
                eval_result.sql = eval_result.refined_sql
                eval_result = await self._execute_sql_internal(eval_result)
            attempts += 1
        if eval_result.execution_success:
            eval_result = await self._generate_summary_internal(
                eval_result,
                intent.raw_query if intent and hasattr(intent, "raw_query") else "",
                intent,
            )
        return ToolResult.ok(
            data={
                "sql": eval_result.sql,
                "rows": eval_result.rows,
                "row_count": eval_result.row_count,
                "execution_success": eval_result.execution_success,
                "execution_error": eval_result.execution_error,
                "diagnosis": eval_result.diagnosis,
                "error_type": eval_result.error_type.value,
                "refined": eval_result.refined,
                "summary": eval_result.summary,
            },
            message="è¯„ä¼°å®Œæˆ" if eval_result.execution_success else "æ‰§è¡Œå¤±è´¥",
        )

    # ---------- ReAct æµç¨‹ï¼šcritique / refine / diagnose_no_data ----------

    async def _build_no_data_guidance(self, user_query: str, diagnosis: dict[str, Any]) -> str:
        prompt = f"""ç”¨æˆ·é—®é¢˜: {user_query}

ç©ºç»“æœè¯Šæ–­:
{json.dumps(diagnosis, ensure_ascii=False, indent=2)}

è¯·ç”¨ä¸­æ–‡ç»™å‡ºä¸€æ®µå‹å¥½è¯´æ˜ï¼š1. ä¸€å¥è¯è§£é‡Šä¸ºä»€ä¹ˆæŸ¥ä¸åˆ°æ•°æ® 2. è¯´æ˜æ˜¯æ•°æ®ä¸å­˜åœ¨è¿˜æ˜¯æ¡ä»¶å†™é”™ 3. 1ï½2 æ¡ä¸‹ä¸€æ­¥å»ºè®®ã€‚ä¸è¶…è¿‡ 200 å­—ã€‚"""
        try:
            text = await self.llm.chat(
                prompt=prompt,
                system_prompt="ä½ æ˜¯æ•°æ®åˆ†æé¡¾é—®ï¼Œå‘ä¸šåŠ¡ç”¨æˆ·è§£é‡Šä¸ºä»€ä¹ˆæŸ¥ä¸åˆ°æ•°æ®ã€‚",
                caller_name="no_data_guidance",
            )
            return text.strip()
        except Exception as e:
            self._log.error(f"ç”Ÿæˆ no_data ç”¨æˆ·æŒ‡å¯¼å¤±è´¥: {e}")
            return "å½“å‰æ¡ä»¶ä¸‹æŸ¥ä¸åˆ°ä»»ä½•æ•°æ®ï¼Œå¯èƒ½æ˜¯æ•°æ®å°šæœªå…¥åº“æˆ–ç­›é€‰æ¡ä»¶è¿‡äºä¸¥æ ¼ã€‚"

    async def _assess_answer_sufficiency(self, state: ReActState) -> None:
        rows = (state.execute_result or {}).get("rows", [])
        if not rows:
            return
        sample = rows[:5] if len(rows) > 5 else rows
        try:
            prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{state.user_query}

å½“å‰æŸ¥è¯¢ç»“æœè¡Œæ•°ï¼š{len(rows)}ã€‚å‰å‡ è¡Œç¤ºä¾‹ï¼š{json.dumps(sample, ensure_ascii=False)}

è¯·åˆ¤æ–­ï¼šä»…å‡­å½“å‰ç»“æœæ˜¯å¦è¶³ä»¥å®Œæ•´ã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Ÿåªè¾“å‡ºä¸€ä¸ªè¯ï¼šsufficient æˆ– insufficientã€‚"""
            resp = await self.llm.chat(
                prompt=prompt,
                system_prompt="æ ¹æ®é—®é¢˜è¯­ä¹‰ä¸ç»“æœå†…å®¹åˆ¤æ–­æ˜¯å¦è¶³ä»¥å›ç­”é—®é¢˜ï¼Œåªè¾“å‡º sufficient æˆ– insufficientã€‚",
                caller_name="assess_answer_sufficiency",
            )
            if "insufficient" in resp.strip().lower():
                state.need_more_analysis = True
                state.reflect("LLMè¯„ä¼°ï¼šå½“å‰ç»“æœä¸è¶³ä»¥å®Œæ•´å›ç­”é—®é¢˜ï¼Œéœ€è¿›ä¸€æ­¥åˆ†æ")
        except Exception as e:
            self._log.warn(f"è¯„ä¼°ç»“æœå……åˆ†æ€§å¤±è´¥: {e}")

    def _pick_dimension_and_metric(self, state: ReActState) -> tuple[str | None, str | None]:
        cols = state.available_columns or []
        if not cols:
            return None, None
        dim_col = None
        metric_col = None
        for c in cols:
            name = c.get("name") or c.get("column_name") or ""
            typ = (c.get("type") or c.get("column_type") or "").upper()
            if not dim_col and ("VARCHAR" in typ or "TEXT" in typ or "STRING" in typ or "CHAR" in typ):
                dim_col = name
            if not metric_col and ("DOUBLE" in typ or "DECIMAL" in typ or "INT" in typ or "NUMERIC" in typ or "FLOAT" in typ or "BIGINT" in typ):
                metric_col = name
            if dim_col and metric_col:
                break
        if not dim_col and cols:
            dim_col = cols[0].get("name") or cols[0].get("column_name")
        return dim_col, metric_col

    async def _generate_probe_queries(
        self, sql: str, table_name: str, schema_text: str | None,
    ) -> list[dict[str, str]]:
        prompt = f"""åˆ†æä»¥ä¸‹ SQL çš„ WHERE æ¡ä»¶ï¼Œç”Ÿæˆæ•°æ®æ¢æµ‹æŸ¥è¯¢æ¥éªŒè¯å„æ¡ä»¶æ˜¯å¦æœ‰æ•°æ®ã€‚

## åŸå§‹ SQL
{sql}

## è¡¨å
{table_name}

## è¡¨ç»“æ„
{schema_text[:1500] if schema_text else "æœªæä¾›"}

## ä»»åŠ¡
1. æå– SQL ä¸­çš„æ¯ä¸ªç­›é€‰æ¡ä»¶
2. ä¸ºæ¯ä¸ªå…³é”®æ¡ä»¶ç”Ÿæˆä¸€ä¸ªæ¢æµ‹æŸ¥è¯¢
3. è¾“å‡º JSON: {{ "probe_queries": [ {{ "purpose": "...", "field": "...", "query": "SELECT ..." }} ] }}"""
        try:
            response = await self.llm.chat(
                prompt=prompt,
                system_prompt="ä½ æ˜¯ SQL åˆ†æä¸“å®¶ï¼Œæ“…é•¿è¯Šæ–­æ•°æ®é—®é¢˜ã€‚",
                caller_name="generate_probe_queries",
            )
            result = parse_json(response)
            return result.get("probe_queries", [])
        except Exception as e:
            self._log.error(f"ç”Ÿæˆæ¢æµ‹æŸ¥è¯¢å¤±è´¥: {e}")
            return []

    async def _execute_probe_queries(
        self, probe_queries: list[dict[str, str]], table_name: str,
    ) -> list[dict[str, Any]]:
        results = []
        for probe in probe_queries:
            query = probe.get("query", "")
            if not query:
                continue
            try:
                rows = await self.db_connector.execute_query(query)
                results.append({
                    "purpose": probe.get("purpose", ""),
                    "field": probe.get("field", ""),
                    "query": query,
                    "success": True,
                    "rows": rows[:20],
                    "row_count": len(rows),
                })
            except Exception as e:
                results.append({
                    "purpose": probe.get("purpose", ""),
                    "field": probe.get("field", ""),
                    "query": query,
                    "success": False,
                    "error": str(e),
                })
        return results

    async def _analyze_probe_results(
        self, original_sql: str, probe_results: list[dict[str, Any]], user_query: str, intent: Any,
    ) -> dict[str, Any]:
        probe_summary = []
        for r in probe_results:
            if r.get("success"):
                values = [list(row.values())[0] if row else None for row in r.get("rows", [])]
                probe_summary.append(f"- {r['purpose']}: æ‰¾åˆ° {r['row_count']} ä¸ªå€¼ï¼Œç¤ºä¾‹: {values[:5]}")
            else:
                probe_summary.append(f"- {r['purpose']}: æŸ¥è¯¢å¤±è´¥ ({r.get('error', '')})")
        prompt = f"""æ ¹æ®æ•°æ®æ¢æµ‹ç»“æœï¼Œè¯Šæ–­ä¸ºä»€ä¹ˆåŸå§‹æŸ¥è¯¢è¿”å›ç©ºç»“æœã€‚

## ç”¨æˆ·é—®é¢˜
{user_query}

## åŸå§‹ SQLï¼ˆè¿”å›ç©ºç»“æœï¼‰
{original_sql}

## æ•°æ®æ¢æµ‹ç»“æœ
{chr(10).join(probe_summary)}

## ä»»åŠ¡
1. åˆ†æå“ªä¸ªæ¡ä»¶å¯¼è‡´äº†ç©ºç»“æœ
2. åˆ¤æ–­æ˜¯"æ•°æ®ç¡®å®ä¸å­˜åœ¨"è¿˜æ˜¯"æ¡ä»¶å†™é”™äº†"
3. å¦‚æœæ˜¯æ¡ä»¶é”™è¯¯ï¼Œç»™å‡ºä¿®æ­£å»ºè®®

## è¾“å‡ºæ ¼å¼ JSON
{{ "conclusion": "...", "root_cause": "no_data_exists|wrong_condition|too_strict|unknown", "details": [], "can_fix": true/false, "fix_reason": "...", "suggested_sql": "..." }}"""
        try:
            response = await self.llm.chat(
                prompt=prompt,
                system_prompt="ä½ æ˜¯æ•°æ®è¯Šæ–­ä¸“å®¶ï¼Œè¯·å®¢è§‚åˆ†æï¼Œä¸è¦çŒœæµ‹ã€‚",
                caller_name="analyze_probe_results",
            )
            return parse_json(response)
        except Exception as e:
            self._log.error(f"åˆ†ææ¢æµ‹ç»“æœå¤±è´¥: {e}")
            return {"conclusion": f"åˆ†æå¤±è´¥: {e}", "root_cause": "unknown", "can_fix": False}

    async def _critique(self, state: ReActState) -> None:
        state.phase = ReActPhase.CRITIQUE
        state.think("å¼€å§‹è¯„ä¼° SQL æ‰§è¡Œç»“æœ")
        sql = state.current_sql or state.final_sql
        if not sql:
            state.set_error("ç¼ºå°‘ SQL", ErrorType.OTHER)
            return
        if not self.db_connector:
            state.set_error("æœªé…ç½®æ•°æ®åº“è¿æ¥", ErrorType.OTHER)
            return
        try:
            rows = await self.db_connector.execute_query(sql)
            state.execute_result = {"rows": rows, "row_count": len(rows)}
            state.execution_error = None
            state.clear_error()
            state.observe(f"æ‰§è¡ŒæˆåŠŸ: {len(rows)} è¡Œ")
            if len(rows) == 0:
                state.set_error("æŸ¥è¯¢è¿”å›ç©ºç»“æœ", ErrorType.NO_DATA)
                state.mark_need(need_critique=True)
            else:
                state.clear_all_needs()
                await self._assess_answer_sufficiency(state)
        except Exception as e:
            state.execution_error = str(e)
            state.observe(f"æ‰§è¡Œå¤±è´¥: {e}")
            error_type = self._classify_error(str(e))
            context = self._extract_error_context(str(e), error_type, state)
            state.set_error(str(e), error_type, context)
            state.refine_attempts += 1

    async def _refine_sql(self, state: ReActState) -> None:
        state.phase = ReActPhase.REFINE
        state.think(f"æ ¹æ®é”™è¯¯ç±»å‹ {state.error_type.value} ä¿®æ­£ SQL")
        eval_result = EvaluationResult(
            sql=state.current_sql,
            execution_error=state.execution_error or state.error,
            error_type=state.error_type,
            error_context=state.error_context,
        )
        eval_result = await self._diagnose_and_refine(
            eval_result, state.intent, state.yml_config, state.schema_text,
        )
        if eval_result.refined and eval_result.refined_sql != state.current_sql:
            state.current_sql = eval_result.refined_sql
            state.reflect(f"SQL å·²ä¿®æ­£: {eval_result.diagnosis}")
            state.mark_need(need_execute=True)
        else:
            state.reflect("æ— æ³•ä¿®æ­£ SQL")

    async def _diagnose_no_data(self, state: ReActState) -> None:
        state.phase = ReActPhase.CRITIQUE
        state.think("æŸ¥è¯¢è¿”å›ç©ºç»“æœï¼Œå¼€å§‹è¯Šæ–­åŸå› ")
        sql = state.current_sql or state.final_sql
        if not sql or not state.table_name:
            state.reflect("ç¼ºå°‘ SQL æˆ–è¡¨åï¼Œæ— æ³•è¯Šæ–­")
            return
        try:
            probe_queries = await self._generate_probe_queries(sql, state.table_name, state.schema_text)
            probe_results = await self._execute_probe_queries(probe_queries, state.table_name)
            diagnosis = await self._analyze_probe_results(
                sql, probe_results, state.user_query, state.intent,
            )
            state.error_context["no_data_diagnosis"] = diagnosis
            state.error_context["no_data_diagnosis_done"] = True
            state.error_context["root_cause"] = diagnosis.get("root_cause")
            state.error_context["can_fix"] = diagnosis.get("can_fix", False)
            state.error_context["suggested_sql"] = diagnosis.get("suggested_sql", "")
            state.error_context["fix_reason"] = diagnosis.get("fix_reason", "")
            state.error_context["user_guidance"] = await self._build_no_data_guidance(
                state.user_query, diagnosis,
            )
            state.reflect(f"ç©ºç»“æœè¯Šæ–­: {diagnosis.get('conclusion', 'æœªçŸ¥åŸå› ')}")
            if diagnosis.get("suggested_sql") and diagnosis.get("can_fix"):
                state.current_sql = _clean_sql_util(diagnosis["suggested_sql"])
                state.mark_need(need_execute=True)
                state.reflect(f"å»ºè®®ä¿®æ­£: {diagnosis.get('fix_reason', '')}")
        except Exception as e:
            self._log.error(f"ç©ºç»“æœè¯Šæ–­å¤±è´¥: {e}")
            state.reflect(f"è¯Šæ–­å¤±è´¥: {e}")

    async def run_generate(self, state: ReActState, context: Any) -> None:
        """è¿è¡Œ SQL ç”Ÿæˆå¹¶å†™å› stateã€‚ä¾› Orchestrator è°ƒç”¨ã€‚"""
        state.phase = ReActPhase.SQL_BUILD
        if not state.intent:
            state.set_error("ç¼ºå°‘æ„å›¾ï¼Œæ— æ³•ç”Ÿæˆ SQL", ErrorType.AMBIGUOUS_INTENT)
            return
        if not self.llm:
            state.set_error("æœªé…ç½® LLMï¼Œæ— æ³•ç”Ÿæˆ SQL", ErrorType.OTHER)
            return
        
        # è·å–å½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼ˆæ¥è‡ª Plannerï¼‰
        current_task = getattr(context, "current_task", None)
        
        result = await self.generate_sql(
            intent=state.intent,
            schema_text=state.schema_text or getattr(context, "schema_text", ""),
            yml_config=state.yml_config or getattr(context, "yml_config", {}),
            available_tables=getattr(context, "available_tables", None),
            current_task=current_task,  # ä¼ é€’ä»»åŠ¡ä¸Šä¸‹æ–‡
            state=state,  # â˜… ä¼ é€’ stateï¼Œç”¨äºè·å–æ³¨å…¥çš„æŒ‡æ ‡å®šä¹‰
        )
        if result.success:
            state.current_sql = result.data.get("sql", "")
            state.sql_candidates = result.data.get("candidates", [])
            state.observe(f"SQL: {state.current_sql[:60]}...")
            state.mark_need(need_sql=False, need_execute=True)
            if hasattr(context, "generated_sql"):
                context.generated_sql = state.current_sql
        else:
            state.set_error(result.error or "SQL ç”Ÿæˆå¤±è´¥", ErrorType.OTHER)

    async def run_execute_and_evaluate(self, state: ReActState, context: Any) -> None:
        """æ‰§è¡Œä¸€æ­¥è¯„ä¼°æµç¨‹ï¼šå…ˆæ‰§è¡Œï¼ˆè‹¥éœ€è¦ï¼‰ï¼Œå† critique/refine/diagnose_no_dataã€‚ä¾› Orchestrator è°ƒç”¨ã€‚"""
        if state.need_execute and not state.execute_result:
            if not self.db_connector:
                state.set_error("æœªé…ç½®æ•°æ®åº“è¿æ¥", ErrorType.OTHER)
                return
            state.phase = ReActPhase.EXECUTE
            sql = state.current_sql
            if not sql:
                state.set_error("ç¼ºå°‘ SQL", ErrorType.OTHER)
                return
            try:
                rows = await self.db_connector.execute_query(sql)
                state.execute_result = {"rows": rows, "row_count": len(rows)}
                state.final_sql = sql
                state.current_sql = sql
                state.clear_error()
                state.observe(f"æ‰§è¡ŒæˆåŠŸ: {len(rows)} è¡Œ")
                if len(rows) == 0:
                    state.set_error("æŸ¥è¯¢è¿”å›ç©ºç»“æœ", ErrorType.NO_DATA)
                    state.mark_need(need_critique=True)
                else:
                    state.clear_all_needs()
                if hasattr(context, "query_result"):
                    context.query_result = rows
                if hasattr(context, "generated_sql"):
                    context.generated_sql = state.final_sql
            except Exception as e:
                state.execution_error = str(e)
                state.observe(f"æ‰§è¡Œå¤±è´¥: {e}")
                error_type = self._classify_error(str(e))
                ctx = self._extract_error_context(str(e), error_type, state)
                state.set_error(str(e), error_type, ctx)
                state.refine_attempts += 1
                state.mark_need(need_execute=False, need_critique=True)
            return
        if state.execution_error:
            await self._critique(state)
            if state.need_refine:
                await self._refine_sql(state)
            return
        if state.error_type == ErrorType.NO_DATA:
            if not state.error_context.get("no_data_diagnosis_done"):
                await self._diagnose_no_data(state)
            return
        if state.has_result:
            state.clear_all_needs()

    async def run_workflow(self, state: ReActState, context: Any) -> None:
        """å®Œæ•´æµç¨‹ï¼šç”Ÿæˆ SQL åæ‰§è¡Œä¸è¯„ä¼°ã€‚ä¾› Orchestrator è°ƒç”¨ã€‚"""
        await self.run_generate(state, context)
        if state.error:
            return
        await self.run_execute_and_evaluate(state, context)


# ---------- è–„åŒ…è£…ï¼ˆä¾› Registry æ³¨å†Œï¼Œæ„é€ ç­¾åä¸å˜ï¼‰ ----------


class ValidateSQLTool(BaseTool):
    """éªŒè¯ SQLã€‚å§”æ‰˜ SQLTool.validate_sqlã€‚"""

    def __init__(self):
        super().__init__(None)
        self._impl = SQLTool(None, None)
        self._log = get_component_logger("ValidateSQLTool")

    @property
    def name(self) -> str:
        return "validate_sql"

    @property
    def description(self) -> str:
        return """éªŒè¯ SQL è¯­å¥çš„è¯­æ³•å’Œä¸šåŠ¡é€»è¾‘ã€‚

ä½¿ç”¨åœºæ™¯ï¼šæ‰§è¡Œå‰å®‰å…¨æ£€æŸ¥ã€ä¸šåŠ¡è§„åˆ™æ ¡éªŒã€‚
è¾“å…¥ï¼šsql, yml_config(å¯é€‰)ã€‚è¾“å‡ºï¼šis_valid, errors, warningsã€‚"""

    @property
    def parameters(self) -> list[ToolParameter]:
        return [
            ToolParameter(name="sql", type="string", description="å¾…éªŒè¯çš„ SQL è¯­å¥", required=True),
            ToolParameter(name="yml_config", type="object", description="ä¸šåŠ¡é…ç½®", required=False),
        ]

    async def execute(
        self,
        sql: str,
        yml_config: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> ToolResult:
        return self._impl.validate_sql(sql=sql, yml_config=yml_config)


class ExecuteSQLTool(BaseTool):
    """æ‰§è¡Œåªè¯» SQLã€‚å§”æ‰˜ SQLTool.execute_sqlã€‚"""

    def __init__(self, db_connector: BaseDatabaseConnector):
        super().__init__(None)
        self._impl = SQLTool(None, db_connector)
        self._log = get_component_logger("ExecuteSQLTool")

    @property
    def name(self) -> str:
        return "execute_sql"

    @property
    def description(self) -> str:
        return """æ‰§è¡Œ SQL æŸ¥è¯¢å¹¶è¿”å›ç»“æœã€‚ä»…æ”¯æŒ SELECTã€‚
è¾“å…¥ï¼šsql, limit(å¯é€‰)ã€‚è¾“å‡ºï¼šrows, row_count, columnsã€‚"""

    @property
    def parameters(self) -> list[ToolParameter]:
        return [
            ToolParameter(name="sql", type="string", description="è¦æ‰§è¡Œçš„ SQL è¯­å¥", required=True),
            ToolParameter(name="limit", type="number", description="è¿”å›è¡Œæ•°é™åˆ¶", required=False, default=100),
        ]

    async def execute(self, sql: str, limit: int = 100, **kwargs: Any) -> ToolResult:
        return await self._impl.execute_sql(sql=sql, limit=limit)


class GenerateSQLTool(BaseTool):
    """ç”Ÿæˆ SQLã€‚å§”æ‰˜ SQLTool.generate_sqlã€‚"""

    def __init__(self, llm: BaseLLM):
        super().__init__(None)
        self._impl = SQLTool(llm, None)
        self._log = get_component_logger("GenerateSQLTool")

    @property
    def name(self) -> str:
        return "generate_sql"

    @property
    def description(self) -> str:
        return """æ ¹æ®ç»“æ„åŒ–æ„å›¾ç”Ÿæˆå¯æ‰§è¡Œçš„ SQLã€‚è¾“å‡ºï¼šä¸» SQLã€å¤šå€™é€‰ã€ä¸šåŠ¡è§£é‡Šã€‚"""

    @property
    def parameters(self) -> list[ToolParameter]:
        return [
            ToolParameter(name="intent", type="object", description="ç»“æ„åŒ–æ„å›¾", required=True),
            ToolParameter(name="schema_text", type="string", description="è¡¨ç»“æ„", required=False),
            ToolParameter(name="yml_config", type="object", description="YAML é…ç½®", required=False),
        ]

    async def execute(
        self,
        intent: "StructuredIntent | dict",
        schema_text: str = "",
        yml_config: dict[str, Any] | None = None,
        available_tables: list[dict] | None = None,
        **kwargs: Any,
    ) -> ToolResult:
        self._log.info("ç”Ÿæˆ SQL...")
        try:
            return await self._impl.generate_sql(
                intent=intent,
                schema_text=schema_text,
                yml_config=yml_config,
                available_tables=available_tables or [],
                **kwargs,
            )
        except Exception as e:
            self._log.error(f"ç”Ÿæˆå¤±è´¥: {e}")
            return ToolResult.fail(str(e))

    async def __call__(
        self,
        state: "ReActState",
        context: "AgentContext",
        **kwargs: Any,
    ) -> None:
        from chatdb.core.react_state import ReActPhase, ErrorType
        state.phase = ReActPhase.SQL_BUILD
        if not state.intent:
            state.set_error("ç¼ºå°‘æ„å›¾ï¼Œæ— æ³•ç”Ÿæˆ SQL", ErrorType.AMBIGUOUS_INTENT)
            return
        result = await self.execute(
            intent=state.intent,
            schema_text=state.schema_text or context.schema_text,
            yml_config=state.yml_config or context.yml_config,
            available_tables=context.available_tables,
        )
        if result.success:
            state.current_sql = result.data.get("sql", "")
            state.sql_candidates = result.data.get("candidates", [])
            state.observe(f"SQL: {state.current_sql[:60]}...")
            state.mark_need(need_sql=False, need_execute=True)
            context.generated_sql = state.current_sql
        else:
            state.set_error(result.error or "SQL ç”Ÿæˆå¤±è´¥", ErrorType.OTHER)


class ExecuteAndEvaluateTool(BaseTool):
    """æ‰§è¡Œ SQL å¹¶è¯Šæ–­/ä¿®æ­£ã€‚å§”æ‰˜ SQLTool.execute_and_evaluateã€‚"""

    def __init__(self, llm: BaseLLM, db_connector: BaseDatabaseConnector):
        super().__init__(None)
        self._impl = SQLTool(llm, db_connector)
        self._log = get_component_logger("ExecuteAndEvaluateTool")

    @property
    def name(self) -> str:
        return "execute_and_evaluate"

    @property
    def description(self) -> str:
        return """æ‰§è¡Œ SQLã€è¯Šæ–­é”™è¯¯ã€åšæœ€å°ä¿®æ­£ã€‚è¾“å‡ºï¼šæ‰§è¡Œç»“æœã€é”™è¯¯è¯Šæ–­ã€ä¿®æ­£å»ºè®®ã€‚"""

    @property
    def parameters(self) -> list[ToolParameter]:
        return [
            ToolParameter(name="sql", type="string", description="è¦æ‰§è¡Œçš„ SQL", required=True),
            ToolParameter(name="schema_text", type="string", description="è¡¨ç»“æ„", required=False),
        ]

    async def execute(
        self,
        sql: str,
        schema_text: str = "",
        intent: Any = None,
        yml_config: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> ToolResult:
        self._log.info(f"æ‰§è¡Œ: {sql[:50]}...")
        try:
            return await self._impl.execute_and_evaluate(
                sql=sql,
                schema_text=schema_text,
                intent=intent,
                yml_config=yml_config or {},
                **kwargs,
            )
        except Exception as e:
            self._log.error(f"æ‰§è¡Œå¤±è´¥: {e}")
            return ToolResult.fail(str(e))

    async def __call__(
        self,
        state: "ReActState",
        context: "AgentContext",
        **kwargs: Any,
    ) -> None:
        from chatdb.core.react_state import ReActPhase, ErrorType
        state.phase = ReActPhase.EXECUTE
        sql = state.current_sql
        if not sql:
            state.set_error("ç¼ºå°‘ SQL", ErrorType.OTHER)
            return
        result = await self.execute(
            sql=sql,
            schema_text=state.schema_text or context.schema_text,
            intent=state.intent,
            yml_config=state.yml_config or context.yml_config,
        )
        if result.data.get("execution_success"):
            rows = result.data.get("rows", [])
            state.execute_result = {"rows": rows, "row_count": len(rows)}
            state.final_sql = result.data.get("sql", sql)
            state.current_sql = state.final_sql
            state.clear_error()
            state.observe(f"æ‰§è¡ŒæˆåŠŸ: {len(rows)} è¡Œ")
            if len(rows) == 0:
                state.set_error("æŸ¥è¯¢è¿”å›ç©ºç»“æœ", ErrorType.NO_DATA)
                state.mark_need(need_critique=True)
            else:
                state.clear_all_needs()
            context.query_result = rows
            context.generated_sql = state.final_sql
        else:
            error = result.data.get("execution_error", "æ‰§è¡Œå¤±è´¥")
            error_type = error_type_from_str(result.data.get("error_type", "other"))
            state.execution_error = error
            state.set_error(error, error_type)
            state.observe(f"æ‰§è¡Œå¤±è´¥: {error}")
            state.mark_need(need_execute=False, need_critique=True)
            if result.data.get("refined") and result.data.get("sql") != sql:
                state.current_sql = result.data.get("sql")
                state.mark_need(need_execute=True)


# ---------- å®Œæ•´æµç¨‹å·¥å…· ----------


class SQLWorkflowTool(BaseTool):
    """å®Œæ•´æµç¨‹ï¼šç”Ÿæˆ â†’ éªŒè¯ â†’ æ‰§è¡Œä¸è¯„ä¼°ã€‚å†…éƒ¨ä½¿ç”¨ä¸€ä¸ª SQLToolã€‚"""

    def __init__(self, llm: BaseLLM, db_connector: BaseDatabaseConnector):
        super().__init__(None)
        self._impl = SQLTool(llm, db_connector)
        self._log = get_component_logger("SQLWorkflowTool")

    @property
    def name(self) -> str:
        return "sql_workflow"

    @property
    def description(self) -> str:
        return """SQL å®Œæ•´æµç¨‹ï¼šæ ¹æ®æ„å›¾ç”Ÿæˆ SQLã€éªŒè¯ã€æ‰§è¡Œå¹¶è¯„ä¼°ã€‚"""

    @property
    def parameters(self) -> list[ToolParameter]:
        return [
            ToolParameter(name="intent", type="object", description="ç»“æ„åŒ–æ„å›¾", required=True),
            ToolParameter(name="schema_text", type="string", description="è¡¨ç»“æ„", required=False),
            ToolParameter(name="yml_config", type="object", description="YAML é…ç½®", required=False),
        ]

    async def execute(
        self,
        intent: "StructuredIntent | dict",
        schema_text: str = "",
        yml_config: dict[str, Any] | None = None,
        available_tables: list[dict] | None = None,
        **kwargs: Any,
    ) -> ToolResult:
        self._log.info("SQL Workflow: ç”Ÿæˆ â†’ éªŒè¯ â†’ æ‰§è¡Œ")
        gen_result = await self._impl.generate_sql(
            intent=intent,
            schema_text=schema_text,
            yml_config=yml_config,
            available_tables=available_tables or [],
            **kwargs,
        )
        if not gen_result.success:
            return gen_result
        sql = gen_result.data.get("sql", "")
        if not sql:
            return ToolResult.fail("SQL ç”Ÿæˆç»“æœä¸ºç©º")
        val_result = self._impl.validate_sql(sql=sql, yml_config=yml_config)
        exec_result = await self._impl.execute_and_evaluate(
            sql=sql,
            schema_text=schema_text,
            intent=intent if hasattr(intent, "raw_query") else None,
            yml_config=yml_config or {},
            **kwargs,
        )
        data = {
            "sql": exec_result.data.get("sql", sql),
            "validation": val_result.data,
            "execution_success": exec_result.data.get("execution_success", False),
            "rows": exec_result.data.get("rows", []),
            "row_count": exec_result.data.get("row_count", 0),
            "diagnosis": exec_result.data.get("diagnosis", ""),
            "refined": exec_result.data.get("refined", False),
            "error_type": exec_result.data.get("error_type", "none"),
        }
        if not exec_result.data.get("execution_success"):
            data["error"] = exec_result.data.get("execution_error") or exec_result.error
        return ToolResult.ok(
            data=data,
            message="Workflow å®Œæˆ" if data["execution_success"] else "æ‰§è¡ŒæœªæˆåŠŸï¼Œå·²è®°å½•è¯Šæ–­",
        )

    async def __call__(
        self,
        state: "ReActState",
        context: "AgentContext",
        **kwargs: Any,
    ) -> None:
        from chatdb.core.react_state import ReActPhase, ErrorType
        state.phase = ReActPhase.SQL_BUILD
        if not state.intent:
            state.set_error("ç¼ºå°‘æ„å›¾ï¼Œæ— æ³•æ‰§è¡Œ SQL æµç¨‹", ErrorType.AMBIGUOUS_INTENT)
            return
        result = await self.execute(
            intent=state.intent,
            schema_text=state.schema_text or context.schema_text,
            yml_config=state.yml_config or context.yml_config,
            available_tables=context.available_tables,
        )
        if not result.success:
            state.set_error(result.error or "SQL æµç¨‹å¤±è´¥", ErrorType.OTHER)
            return
        d = result.data
        state.current_sql = d.get("sql", "")
        state.final_sql = state.current_sql
        state.sql_candidates = []
        if d.get("execution_success"):
            rows = d.get("rows", [])
            state.execute_result = {"rows": rows, "row_count": d.get("row_count", 0)}
            state.clear_error()
            state.observe(f"æ‰§è¡ŒæˆåŠŸ: {len(rows)} è¡Œ")
            if len(rows) == 0:
                state.set_error("æŸ¥è¯¢è¿”å›ç©ºç»“æœ", ErrorType.NO_DATA)
                state.mark_need(need_critique=True)
            else:
                state.clear_all_needs()
            context.query_result = rows
            context.generated_sql = state.final_sql
        else:
            state.execution_error = d.get("error", "æ‰§è¡Œå¤±è´¥")
            state.set_error(state.execution_error, error_type_from_str(d.get("error_type", "other")))
            state.observe(f"æ‰§è¡Œå¤±è´¥: {state.execution_error}")
            state.mark_need(need_execute=False, need_critique=True)
        state.mark_need(need_sql=False)
